<0.13.10.92.16.41.26.tmeadows@resumix.portal.com (<speaker>Tim Meadows</speaker>).0>
Type:     cmu.cs.robotics
Who:      <speaker>Gregory D</speaker>. Hager - 
          Department of Computer Science
          Yale University
Topic:    Techniques for Task-Directed Sensor Data 
          Fusion and Sensor Planning
<speaker>Dates</speaker>:    16-Oct-92
Time:     3:30 - <etime>5:00 PM</etime>
Place:    <speaker>DOHERTY HALL</speaker> 2315 (*NOTE ROOM*)
PostedBy: tmeadows on 13-Oct-92 at 16:41 from resumix.portal.com (<speaker>Tim Meadows</speaker>)
Abstract: 

RI SEMINAR

 <speaker>WHEN</speaker>:		Friday, 16 Ocotober 1992, 3:30 - <etime>5:00 pm</etime>
		Refreshments to be served by <stime>3:15 pm</stime>

 <speaker>WHERE</speaker>:		<speaker>DOHERTY HALL</speaker> 2315 (*NOTE ROOM*)

 SPEAKER:		<speaker>Gregory D</speaker>. Hager - 
 		Department of Computer Science
 	 	Yale University

 TITLE:		Techniques for Task-Directed Sensor Data 
 		Fusion and Sensor Planning

The growing popularity of flexible, high-bandwidth sensing in robotic systems has posed many new problems for the control of sensors and sensor information processing.  <paragraph><sentence>My approach to these problems assumes that the objective of sensing is to minimize effort while maximizing the likelihood of a good or correct decision.</sentence>  <sentence>In general, any further quantification of the latter depends heavily on the specifics of a given robot task, so I refer to this approach as ``task-directed'' sensing.</sentence></paragraph>

<paragraph><sentence>This talk describes and compares two complementary approaches to solving task-directed sensing problems.</sentence>  <sentence>The first approach employs decision-theoretic methods for quantifying the value of sensor information, and relies on a novel, grid-based approximation to <speaker>Bayes</speaker>' theorem for combining information and representing uncertainty.</sentence>  <sentence>I describe the application of these methods to a tracking-based vision system with controllable focus of attention and briefly present some experimental results.</sentence></paragraph>

<paragraph><sentence>The second approach employs a set-based representation of uncertainty.</sentence> <sentence><speaker>Rather</speaker> than optimizing a statistical criterion, the goal of this method is to satisfy a system of inequality constraints that represent both sensor information and task-specific decision criteria.</sentence>  <sentence>While doing so, the system adapts its data processing and data representation to the available sensor data and decision criteria.</sentence>  I show several examples, taken from the manipulation domain, where adding task constraints to the sensing probl

em significantly improves processing performance.  <sentence>In situations where multiple objects are present, this adaptation leads to a natural, task-directed, focus-of-attention mechanism.</sentence></paragraph>

<paragraph><sentence><speaker>Finally</speaker>, depending on time and interest, I <speaker>will briefly discuss work</speaker> on generalizing set-based methods to unstructured environments, and also outline recent work in sensor planning for controlling actions.</sentence></paragraph>

Hosted By:  <speaker>Hagen Schempf</speaker>,  x6884

****************|**************************|**************************
*               |                          |                         *
*<speaker>Tim Meadows</speaker>    |  Field Robotics Center   | Carnegie Mellon Univ.   *
*               |                          |                         *
*412-268-7085   |  Fax: 412-682-1793       | tmeadows@frc.ri.cmu.edu *
*               |                          |                         *
**********************************************************************

